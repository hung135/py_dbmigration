#This file is to configure mapping of files to database tables
# Make sure you don't use Double Quotes as special characters will be escaped
# order matters as the file will only get processed once to the first regex-pattern that matches
#file_encoding: default to UTF8
#import_method: #  'IMPORT_VIA_PANDAS': pandas library,  'IMPORT_VIA_CLIENT_CLI': commandline utility native to db connection
# need to implement line by line import for rough data files
#process_order:  make up a number to control the order in which the files get processed
#new_delimiter parameter will replace whatever parameter in the file and attemp to escape and quotes
#regex takes into account full path string
# NB: The files in this dataset are not CSV compliant....they have not escaped double quotes
- path: '/home/dtdata/source_data/mkts_derived_data_warehouse/experian_mir/'
  enabled: False # activates this configration tree
  project_name: wyman
  process_logic: # this will get executed for all files
    - logic: 'custom_logic.generate_checksum'
    - logic: 'custom_logic.log_file_size'
    - logic: 'custom_logic.abort_if_duplicate'
  reset_failed: False
  mapping:
    - file_regex: '.*Datapacks.zip$'
      file_type: 'ZIP'
      process_logic: # this will get executed for all files of this type matching the regex
        - logic: 'custom_logic.extract_compressed_file'
    - file_regex: '.*DataPack.xlsx$'
      file_type: 'XLSX'
      schema_name: 'stg'
      table_name: 'wyman'
      file_delimiter: ","
      column_list: None
      process_logic: # this will get executed for all files of this type matching the regex
        - logic: 'custom_logic.wyman'
      use_header: False
      has_header: True
      quoted_header: False
      header_row_location: 0
      append_file_id: False
      file_encoding: 'ISO-8859-1'
      limit_rows: None
      pre_action:
        - sql: 'truncate table stg.wyman cascade'
      post_action:
        - sql: "insert into autocount.dd_lookup( name,type)
                select distinct units,'unit' from stg.wyman a
                left outer join autocount.dd_lookup b on b.name=a.units and type='unit'
                where b.id is null
                union
                select distinct figure,'figure' from stg.wyman a
                left outer join autocount.dd_lookup b on b.name=a.figure and type='figure'
                where b.id is null
                union
                select distinct sheetname,'sheetname' from stg.wyman a
                left outer join autocount.dd_lookup b on b.name=a.sheetname and type='sheetname'
                where b.id is null
                union
                select distinct dimension,'dimension' from stg.wyman a
                left outer join autocount.dd_lookup b on b.name=a.dimension and type='dimension'
                where b.id is null
                union
                select distinct measure,'measure' from stg.wyman a
                left outer join autocount.dd_lookup b on b.name=a.measure and type='measure'
                where b.id is null"
        - sql: "insert into autocount.wyman(file_id,sheetname,figure,dimension,measure,units,stat_value)
                select a.file_id,
                  b.id,
                  c.id,
                  d.id,
                  e.id,
                  f.id,
                  a.stat_value
                from stg.wyman a
                inner  join autocount.dd_lookup b on b.type='sheetname' and b.name=a.sheetname
                inner  join autocount.dd_lookup c on c.type='figure' and c.name=a.figure
                inner  join autocount.dd_lookup d on d.type='dimension' and d.name=a.dimension
                inner  join autocount.dd_lookup e on e.type='measure' and e.name=a.measure
                inner  join autocount.dd_lookup f on f.type='unit' and f.name=a.units"
        - sql: "vacuum analyze autocount.wyman"
- path: '/home/data/projects/autocount/'
  enabled: True # activates this configration tree
  project_name: autocount
  process_logic: # this will get executed for all files
    - logic: 'custom_logic.generate_checksum'
    - logic: 'custom_logic.log_file_size'
    - logic: 'custom_logic.abort_if_duplicate'

  mapping:
    - file_regex: '/home/data/projects/autocount/20.*_CFPB_Risk.zip$'
      enabled: False
      file_type: 'ZIP'
      process_logic: # this will get executed for all files of this type matching the regex
        - logic: 'custom_logic.extract_compressed_file'
    - file_regex: '/home/data/projects/autocount/20.*_CFPB_Marketshare.zip$'
      enabled: True
      file_type: 'ZIP'
      unzip_again: True
      process_logic: # this will get executed for all files of this type matching the regex
        - logic: 'custom_logic.extract_compressed_file'
      file_password : None
    - file_regex: '.*CFPB_Marketshare.*.csv$'
      enabled: True
      process_logic: # this will get executed for all files of this type matching the regex
        #- logic: 'custom_logic.client_copy'
        - logic: 'custom_logic.pandas_import'
      file_type: 'CSV'
      process_order: 1
      table_name: 'marketshare'
      file_delimiter: ","
      column_list: "dealer,lender,lender_type,state,zip,month,year,dealer_type,new_used,count_total,transaction_type"
      schema_name: 'autocount'
      use_header: False
      has_header: True
      quoted_header: False
      header_row_location: 0
      append_file_id: True
      file_encoding: 'ISO-8859-1' 

      #pre_action_sql: 'truncate table autocount.marketshare cascade'
      limit_rows: None
      post_action:
        - sql: "update autocount.marketshare set file_id={file_id} where file_id=0"
        - sql: "vacuum analyze {schema_name}.{table_name}"
      #new_delimiter: '|'
    - file_regex: '.*CFPB_Risk.*.csv$'
      enabled: False
      file_type: 'CSV'
      process_logic: # this will get executed for all files of this type matching the regex
        - logic: 'custom_logic.client_copy'
      table_name: 'risk'
      file_delimiter: ","
      column_list: "dealer,lender,lender_type,state,zip,month,year,dealer_type,new_used,credit_tier,count_scored,payment,rate,rate_count,term,amt_fin,amt_fin_count,value,value_count,ltv,ltv_count"
      schema_name: 'autocount'
      use_header: False
      has_header: True
      quoted_header: False
      header_row_location: 0
      append_file_id: True
      file_encoding: 'ISO-8859-1'
      import_method: 'client_copy2'
      #pre_action_sql: ''
      limit_rows: None
      #new_delimiter: '|'